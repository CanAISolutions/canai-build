# CanAI Test Debugging Best Practices Rule

## Purpose
Ensure all test debugging and test file changes follow a standardized, scientific, and analytical workflow, maximizing efficiency and reliability while minimizing risk to existing passing suites.

## Requirements
- **Follow the documented workflow in [test-debugging-best-practices.md](mdc:docs/test-debugging-best-practices.md)** for all test debugging, failures, or changes.
- **Logging-first:** Instrument code with robust, privacy-conscious logging before making changes or fixing failures.
- **Diagnostics:** Use logs and diagnostics to analyze root causes before code rewrites.
- **Research-based:** Study recent code changes, the scope of modifications, and related documentation before acting.
- **Incremental Testing:** Run tests frequently and incrementally, especially before touching existing passing suites.
- **Evidence-driven:** Only make code changes after gathering sufficient evidence from logs, test output, and code review.
- **Documentation:** Update lessons learned in the best practices doc after each significant debugging session.

## Advanced Requirements
- **Structured Logging:** Use a custom logger for test diagnostics where possible.
- **Test Isolation:** Use `.only` and focused runs to isolate failures during debugging.
- **Deterministic Tests:** Mock randomness, timestamps, and external dependencies.
- **Test Hooks:** Leverage Vitest's hooks (e.g., `context.onTestFailed`) for automated diagnostics.
- **Stepwise Assertions:** Break complex tests into smaller, granular assertions.

See the 'Advanced Vitest Debugging Techniques' section in [test-debugging-best-practices.md](mdc:docs/test-debugging-best-practices.md) for details.

## Implementation Guidance
- Reference [docs/test-debugging-best-practices.md](mdc:docs/test-debugging-best-practices.md) for the full workflow and rationale.
- Align with PRD, project standards, and CI/CD quality gates.
- Encourage a culture of continuous improvement and knowledge sharing.

## Validation
- CI/CD and code review must check for adherence to this rule when test files are changed or test failures are addressed.
- Automated or manual checks should confirm that logging, diagnostics, and incremental testing are present in the workflow.

## Preventative Practices
- **Colocate Tests:** Test files must be placed next to the modules they test.
- **Consistent Naming:** All test files must use `.spec.ts`, `.spec.js`, `.test.ts`, or `.test.js` suffixes.
- **AAA Pattern:** All tests must follow the Arrange-Act-Assert structure.
- **Mock External Dependencies:** Network, database, and external services must be mocked.

## Anti-Patterns to Avoid
- **Global State:** Do not rely on or mutate global state between tests.
- **Test Interdependence:** Each test must be fully independent.
- **Overuse of beforeAll:** Prefer `beforeEach` for setup.
- **Unclear Test Names:** Test names must clearly describe the scenario and expected outcome.

See the 'Preventative Practices' and 'Common Anti-Patterns to Avoid' sections in [test-debugging-best-practices.md](mdc:docs/test-debugging-best-practices.md) for details.

## Additional Required Practices
- **Explicit Assertions:** All tests must use explicit, specific assertions (`toBe`, `toEqual`, `expect.soft`).
- **Type Safety:** TypeScript code must include `expectTypeOf` or `assertType` tests for new/changed types.
- **Test Isolation:** Use `vi.mock`, `vi.resetModules`, and proper hooks to ensure isolation and state reset.
- **Descriptive Naming:** `describe`/`it` blocks must use clear, consistent naming reflecting feature/module and expected behavior.
- **Error Assertions:** Always assert on specific error types/messages/codes.
- **Enhanced Logging:** Add targeted logging for diagnostics on failure.
- **Interactive Debugging:** Use breakpoints, `--inspect-brk`, and disable parallelism for complex debugging.
- **Chain Effect Analysis:** Review recent code changes and dependencies when diagnosing failures.
- **Baseline Validation:** Scaffold minimal test files, initial snapshots, and type tests for all new files; require human review of snapshots.
- **Automated Fix/Recovery:** Offer concrete code fixes and recommend git rollback if needed.
- **Vitest Reporters:** Configure `vitest.config.ts` with `json`, `html`, and `verbose` reporters.
- **Agent Explanations:** Add comments and commit messages explaining agent-driven changes.

## Expanded Anti-Patterns to Avoid
- **Flaky Tests:** No arbitrary timers, control randomness, stable mocks.
- **Snapshot Overuse:** Use snapshots judiciously, always review on creation.
- **Direct DOM Manipulation:** Prefer testing libraries over direct DOM access.
- **Excessive/Brittle Mocks:** Mock only what's necessary, prefer module-level mocks.

See the updated 'Success Checklist' in [test-debugging-best-practices.md](mdc:docs/test-debugging-best-practices.md) for a summary of all required standards.

## Additional Mandatory Practices (2025-07-09)

The following requirements are **new** and derived from `docs/test-advice.md` to strengthen our Vitest strategy. They are *immediately enforceable* and apply to every interaction that creates **or** modifies a `*.test.*` / `*.spec.*` file.

### Gold-Standard Example File
- A canonical reference test must live at `tests/_example.gold.spec.ts`.  All new tests should follow its structure & naming conventions.

### Fail-Fast Misconfiguration Guard
- `vitest --typecheck` **and** project ESLint rules **must** run (and pass) as part of every `vitest` invocation in CI.
- Any test run that reports TypeScript, ESLint, or Vitest configuration warnings is treated as a failure.

### Observability & Logging
- `vitest.config.ts` **must** include `verbose`, `json`, and `html` reporters.  CI pipelines should upload the generated artifacts.
- Treat *all* unhandled promise rejections and console warnings as failures.
- Add targeted `console.error`/`debug` logs (or `debug` library) around complex assertions; strip noisy logs in passing builds.
- Configure per-test and global timeouts; flag tests executing >80 % of limit for review.

### Recovery Procedures & CI Safety Nets
- Implement **robust teardown** via `afterEach`/`afterAll` to release resources.
- Adopt **snapshot discipline**: update snapshots only with explicit human review; PR diffs must show changes.
- Enable `--retry=2` (CI only) and quarantine flaky tests for triage.
- Require a clean `git` state before AI-driven edits; encourage frequent commits & easy rollbacks (`git reset --hard`).
- Full suite (with coverage) must run across supported Node versions & OSes on every push; any failure is blocking.

### Rapid-Fire Checklist Enforcement
Integrate the **Vitest & Cursor AI Success Checklist** (see `docs/test-debugging-best-practices.md`) into CI linting so that any guideline violation surfaces as an actionable error.

### Planning-Phase Enforcement

- **Test Design Doc Required:** For each new feature or task that will introduce or modify production code, a lightweight test plan document (`<feature>-test-plan.md`) must be created **before** implementation begins.  The doc must outline:
  1. Target modules/files
  2. Test scope (unit / integration / e2e)
  3. Edge-cases & negative scenarios
  4. Expected logging/observability hooks
- **Taskmaster Hook:** Any Taskmaster task that represents production code MUST have an auto-generated dependent subtask titled `Create Vitest skeleton for <module>`.
- **Rule Invocation:** By extending the rule's context globs (see `.cursor.config.json`) to include `docs/**/*test*.md` and `.taskmaster/tasks/**/*.json`, this rule is now evaluated at planning time—catching issues *before* the first test line is written.

### Skeleton Template Requirement

- A canonical template lives at `tests/_example.gold.spec.ts` (see repository root).  New tests **must** be scaffolded from this template to guarantee AAA structure, descriptive naming, and explicit assertions.

### Progressive Coverage Enforcement

Early-stage development often starts with low overall coverage.  Adopt a *ratcheting* approach:

| Baseline Coverage | CI Behaviour |
|-------------------|--------------|
| < 40 %            | Emit **warning** only; allow merge but annotate PR with uncovered lines. |
| 40 % – 80 %       | Fail CI if coverage **drops**; allow merge if equal or higher. |
| ≥ 80 %            | Enforce target: fail if total coverage < 80 % or the delta of changed lines < 80 %. |

Configure Vitest + `vitest-coverage-report` (or Istanbul) in CI to implement this step-function.

> **Note:** These thresholds may be adjusted in `.taskmaster/config.json` once PRD tasks reach ≥70 % completion.

---
**Created:** 2025-07-09
**Version:** 1.0.0
**Alignment:** PRD Sections 13.1, 14.1, project QA standards
description:
globs:
alwaysApply: false
---
